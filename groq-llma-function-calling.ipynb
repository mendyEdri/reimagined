{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "client = Groq(\n",
    "    api_key=os.environ['GROQ_API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\"\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-groq-8b-8192-tool-use-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's data-driven world because they enable efficient processing and analysis of vast amounts of text data. Here are some key reasons why they're important:\n",
      "\n",
      "1. **Speed and Efficiency**: Fast language models can process and generate text at incredible speeds, making them ideal for applications where time is of the essence, such as real-time chatbots, search engines, and content generation tools.\n",
      "2. **Scalability**: These models can handle large volumes of data, allowing them to be used in applications that require processing massive datasets, like data analytics and machine learning.\n",
      "3. **Improved Accuracy**: By leveraging advanced algorithms and training on vast amounts of data, fast language models can achieve higher accuracy in understanding and generating text, leading to better performance in tasks like language translation and text summarization.\n",
      "4. **Enhanced User Experience**: Fast language models can power applications that provide instant responses, personalized recommendations, and intuitive interfaces, enhancing user satisfaction and engagement.\n",
      "5. **Advancements in AI Research**: The development and improvement of fast language models drive advancements in artificial intelligence research, pushing the boundaries of what is possible in natural language processing and beyond.\n",
      "6. **Automation and Productivity**: By automating tasks that previously required human intervention, fast language models can significantly increase productivity and efficiency in industries like customer service, content creation, and data analysis.\n",
      "7. **Cost Savings**: Automating tasks with fast language models can reduce labor costs and minimize the need for manual data processing, making them a cost-effective solution for businesses.\n",
      "\n",
      "In summary, fast language models are essential for speeding up the processing and analysis of text data, enhancing user experience, and driving advancements in AI research, all while providing cost savings and increased productivity.\n"
     ]
    }
   ],
   "source": [
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Use with Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessageToolCall(id='call_47jp', function=Function(arguments='{\"expression\": \"25*4+10-9.11\"}', name='calculate'), type='function')\n",
      "25*4+10-9.11\n",
      "The result of 25 x 4 + 10 - 9.11 is 100.89.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import json\n",
    "\n",
    "client = Groq()\n",
    "MODEL = 'llama3-groq-70b-8192-tool-use-preview'\n",
    "\n",
    "def calculate(expression):\n",
    "    \"\"\"Evaluate a mathematical expression\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        print(expression)\n",
    "        return json.dumps({\"result\": result})\n",
    "    except:\n",
    "        return json.dumps({\"error\": \"Invalid expression\"})\n",
    "\n",
    "def run_conversation(user_prompt):\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a calculator assistant. Use the calculate function to perform mathematical operations and provide the results.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"calculate\",\n",
    "                \"description\": \"Evaluate a mathematical expression\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The mathematical expression to evaluate\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"expression\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "        max_tokens=4096\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    if tool_calls:\n",
    "        available_functions = {\n",
    "            \"calculate\": calculate,\n",
    "        }\n",
    "        messages.append(response_message)\n",
    "        for tool_call in tool_calls:\n",
    "            print(tool_call)\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                expression=function_args.get(\"expression\")\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages\n",
    "        )\n",
    "        return second_response.choices[0].message.content\n",
    "\n",
    "user_prompt = \"What is 25 x 4 + 10 - 9.11?\"\n",
    "print(run_conversation(user_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessageToolCall(id='call_1x55', function=Function(arguments='{\"expression\": \"6^2\"}', name='calculate'), type='function')\n",
      "6^2\n",
      "6 squared is 36.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"What is 6 squared?\"\n",
    "print(run_conversation(user_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duckduckgo_search\n",
    "!pip install wikipedia\n",
    "!pip install request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessageToolCall(id='call_t9jv', function=Function(arguments='{\"query\": \"capital of Italy\"}', name='wikipedia_search'), type='function')\n",
      "Using Wikipedia for capital of Italy\n",
      "ChatCompletionMessageToolCall(id='call_n62b', function=Function(arguments='{\"query\": \"famous landmark in Italy\"}', name='wikipedia_search'), type='function')\n",
      "Using Wikipedia for famous landmark in Italy\n",
      "The capital of Italy is Rome. You can find more information about Rome [here](https://en.wikipedia.org/wiki/Rome). For famous landmarks, I recommend checking out the Colosseum or the Vatican Museums.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import wikipedia\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "\n",
    "def duckduckgo_search(query):\n",
    "    \"\"\"\"Perform a DuckDuckGo search using the duckduckgo_search library\"\"\"\n",
    "    print(f\"using DDG for {query}\")\n",
    "\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            results = list(ddgs.text(query, max_results=3))\n",
    "\n",
    "        if not results:\n",
    "            return f\"No results found for '{query}. the search may have been to specific or there might be no relevant information available.\"\n",
    "        \n",
    "        # formatted_results = \"\\n\".join([f\"-{result['title']}: {result[\"body\"]}\" for result in results])\n",
    "        formatted_results = \"\\n\".join([f\"-{result['title']}: {result['body']}\" for result in results])\n",
    "        return f\"Here are some search results for '{query}:\\n{formatted_results}'\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while search for '{query}': {str(e)}\"\n",
    "\n",
    "def wikipedia_search(query):\n",
    "    \"\"\"Perform a Wikipedia search\"\"\"\n",
    "    try:\n",
    "        print(f\"Using Wikipedia for {query}\")\n",
    "        page = wikipedia.page(query)\n",
    "        summary = wikipedia.summary(query, sentences=2)\n",
    "        return json.dumps({\"title\": page.title, \"summary\": summary, \"url\": page.url})\n",
    "    except:\n",
    "        return json.dumps({\"error\": \"No Wikipedia page found for the query\"})\n",
    "\n",
    "\n",
    "def run_conversation(user_prompt):\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a search assistant. Use the duckduckgo_search function to perform web \\\n",
    "            searches and the wikipedia_search function to find information on Wikipedia. if you don't \\\n",
    "            need either of these then just reply normally\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"internet_search\",\n",
    "                \"description\": \"Perform a DuckDuckGo search\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The search query\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": \"query\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"wikipedia_search\",\n",
    "                \"description\": \"Perform a Wikipedia search\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The search query\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"]\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "        max_tokens=4096\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    if tool_calls:\n",
    "        available_functions = {\n",
    "            \"internet_search\": duckduckgo_search,\n",
    "            \"wikipedia_search\": wikipedia_search,\n",
    "        }\n",
    "        messages.append(response_message)\n",
    "        for tool_call in tool_calls:\n",
    "            print(tool_call)\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                query=function_args.get(\"query\")\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages\n",
    "        )\n",
    "        return second_response.choices[0].message.content\n",
    "\n",
    "\n",
    "user_prompt = \"What is the capital of Italy and what's a famous landmark there?\"\n",
    "print(run_conversation(user_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessageToolCall(id='call_zg7q', function=Function(arguments='{\"query\": \"latest news about Tel Aviv\"}', name='duckduckgo_search'), type='function')\n",
      "using DDG for latest news about Tel Aviv\n",
      "Here are the latest news about Tel Aviv:\n",
      "1. \"Explosion in Tel Aviv Kills at Least One\" by The New York Times: An explosion in central Tel Aviv killed at least one person and injured several others, the Israeli authorities said early Friday morning. A preliminary investigation indicated that a falling object might have caused the blast.\n",
      "2. \"Tel Aviv, Israel, explosion near US Embassy branch office kills one\" by an unknown source: An explosion near the US Embassy branch office in Tel Aviv that killed at least one person early Friday is being investigated as a possible drone attack, according to Israeli authorities.\n",
      "3. \"Israeli military says Tel Aviv blast apparently caused by drone\" by Reuters: People walk down the stairs of a building damaged at the site of an explosion, amid the Israel-Hamas conflict in Tel-Aviv, Israel July 19, 2024.\n"
     ]
    }
   ],
   "source": [
    "# user_prompt = \"What just happened in Tel Aviv?\"\n",
    "# print(run_conversation(user_prompt))\n",
    "\n",
    "user_prompt = \"What are the latest news about Tel Aviv?\"\n",
    "print(run_conversation(user_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = f\"\"\"\n",
    "#             Create a 5 levels of thinking.\n",
    "#             1st, dumb and stupid\n",
    "#             2st, easy and not deep.\n",
    "#             3nd, medium.\n",
    "#             4rd, hard.\n",
    "#             5th, complex and creative.\n",
    "#             6th, mind-blowing, never heard such an idea, out of the world idea, 250iq idea.\n",
    "\n",
    "#             include setp-by-step guide how to achive the best option.\n",
    "\n",
    "#             Question: how to solve the traffic jams in the city?\n",
    "#             Answer:\n",
    "#         \"\"\"\n",
    "\n",
    "# content = llm.chat.completions.create(\n",
    "#     model=modelName, \n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": question\n",
    "#         },\n",
    "#     ],\n",
    "#     # response_format={\"type\": \"json_object\"}\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
